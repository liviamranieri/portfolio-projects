{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.906"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timeit\n",
    "\n",
    "# Student Name : Sophie Briques\n",
    "# Cohort       : Castro - 3\n",
    "\n",
    "################################################################################\n",
    "# Import Packages\n",
    "################################################################################\n",
    "\n",
    "# importing libraries\n",
    "import pandas            as pd                       # data science essentials\n",
    "import numpy             as np\n",
    "from sklearn.model_selection import train_test_split # train-test split\n",
    "from sklearn.metrics import roc_auc_score            # auc score\n",
    "\n",
    "# CART model packages\n",
    "from sklearn.tree import DecisionTreeClassifier      # classification trees\n",
    "\n",
    "#Grid Search\n",
    "from sklearn.model_selection import GridSearchCV     # hyperparameter tuning\n",
    "from sklearn.metrics import make_scorer              # customizable scorer\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Load Data\n",
    "################################################################################\n",
    "\n",
    "# specifying file name\n",
    "file = \"Apprentice_Chef_Dataset.xlsx\"\n",
    "\n",
    "# reading the file into Python\n",
    "original_df = pd.read_excel(file)\n",
    "chef_org = original_df.copy()\n",
    "\n",
    "################################################################################\n",
    "# Feature Engineering and (optional) Dataset Standardization\n",
    "################################################################################\n",
    "\n",
    "#################################################\n",
    "##########  User-Defined Functions    ###########\n",
    "#################################################\n",
    "\n",
    "##########  Defining function to flag high outliers in variables\n",
    "def outlier_flag_hi(variable, threshold, data):\n",
    "    \"\"\"\n",
    "    This function is used to flag high outliers in a dataframe the variables' \n",
    "    outliers by creating a new column that is preceded by 'out_'.\n",
    "\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    variable  : str, continuous variable.\n",
    "    threshold : float, value that will identify where outliers would be.\n",
    "    data      : dataframe, where the variables are located.\n",
    "    \n",
    "    \"\"\"\n",
    "    # creating a new column\n",
    "    data['out_' + variable + '_hi'] = 0\n",
    "        \n",
    "    # defining outlier condition\n",
    "    high = data.loc[0:,'out_' + variable + '_hi'][data[variable] > threshold]\n",
    "        \n",
    "    # imputing 1 inside flag column\n",
    "    data['out_' + variable + '_hi'].replace(to_replace = high,\n",
    "                                    value   = 1,\n",
    "                                    inplace = True)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "##########  Defining function to flag high outliers in variables\n",
    "def outlier_flag_lo(variable, threshold, data):\n",
    "    \"\"\"\n",
    "    This function is used to flag low outliers in a dataframe the variables' \n",
    "    outliers by creating a new column that is preceded by 'out_'.\n",
    "\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    variable  : str, continuous variable.\n",
    "    threshold : float, value that will identify where outliers would be.\n",
    "    data      : dataframe, where the variables are located.\n",
    "    \n",
    "    \"\"\"\n",
    "    # creating a new column\n",
    "    data['out_' + variable + '_lo'] = 0\n",
    "        \n",
    "    # defining outlier condition\n",
    "    low = data.loc[0:,'out_' + variable + '_lo'][data[variable] < threshold]\n",
    "        \n",
    "    # imputing 1 inside flag column\n",
    "    data['out_' + variable + '_lo'].replace(to_replace = low,\n",
    "                                    value   = 1,\n",
    "                                    inplace = True)\n",
    "    # Defining function to flag higher variables\n",
    "def success_flag(variable, threshold, data):\n",
    "    \"\"\"\n",
    "    This function is used to flag in a dataframe the variables' trend changes \n",
    "    above a threshold by creating a new column that is preceded by 'success_'.\n",
    "\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    variable  : str, continuous variable.\n",
    "    threshold : float, value that will identify after which the trend on variable y changes\n",
    "    data      : dataframe, where the variables are located.\n",
    "    \n",
    "    \"\"\"\n",
    "    new_column = 'success_' + variable\n",
    "    \n",
    "    # creating a new column\n",
    "    data[new_column] = 0\n",
    "        \n",
    "    # defining outlier condition\n",
    "    high = data.loc[0:,new_column][data[variable] > threshold]\n",
    "        \n",
    "    # imputing 1 inside flag column\n",
    "    data[new_column].replace(to_replace = high,\n",
    "                             value   = 1,\n",
    "                             inplace = True)\n",
    "\n",
    "\n",
    "#################################################\n",
    "#############  Feature Engineering    ###########\n",
    "#################################################\n",
    "\n",
    "# Flagging missing variables for FAMILY_NAME\n",
    "# creating a copy of dataframe for safety measures\n",
    "chef_m = chef_org.copy()\n",
    "\n",
    "# creating a new column where 1 indicates that observation has a missing family name\n",
    "chef_m['m_FAMILY_NAME'] = chef_m['FAMILY_NAME'].isnull().astype(int)\n",
    "\n",
    "# imputing missing values\n",
    "chef_m['FAMILY_NAME'] = chef_m['FAMILY_NAME'].fillna('Unknown')\n",
    "\n",
    "# Establishing outliers thresholds for analysis\n",
    "# Continous\n",
    "avg_time_per_site_visit_hi = 200\n",
    "avg_prep_vid_time_hi       = 250\n",
    "followed_rec_hi            = 75\n",
    "followed_rec_lo            = 10 \n",
    "largest_order_size_hi      = 5\n",
    "avg_clicks_per_visit_hi    = 17\n",
    "avg_clicks_per_visit_lo    = 11\n",
    "median_meal_hi             = 3\n",
    "\n",
    "# Counts:\n",
    "total_meals_ordered_hi            = 320\n",
    "unique_meals_purchased_hi         = 8\n",
    "unique_meals_purchased_lo         = 2\n",
    "contacts_with_customer_service_hi = 13\n",
    "cancellations_before_noon_hi      = 8\n",
    "late_deliveries_hi                = 17\n",
    "total_photos_viewed_hi            = 800\n",
    "products_viewed_hi                = 9 \n",
    "products_viewed_lo                = 2 \n",
    "median_meal_lo                    = 2\n",
    "\n",
    "# Target Variable\n",
    "revenue_hi  =  5500\n",
    "\n",
    "\n",
    "# Creating Dictionary to link variables with outlier thresholds\n",
    "lst_thresholds_hi = {\n",
    "    'AVG_TIME_PER_SITE_VISIT'      : avg_time_per_site_visit_hi,\n",
    "    'AVG_PREP_VID_TIME'            : avg_prep_vid_time_hi,\n",
    "    'TOTAL_MEALS_ORDERED'          : total_meals_ordered_hi,\n",
    "    'UNIQUE_MEALS_PURCH'           : unique_meals_purchased_hi,\n",
    "    'CONTACTS_W_CUSTOMER_SERVICE'  : contacts_with_customer_service_hi,\n",
    "    'CANCELLATIONS_BEFORE_NOON'    : cancellations_before_noon_hi,\n",
    "    'LATE_DELIVERIES'              : late_deliveries_hi,\n",
    "    'TOTAL_PHOTOS_VIEWED'          : total_photos_viewed_hi,\n",
    "    'REVENUE'                      : revenue_hi,\n",
    "    'FOLLOWED_RECOMMENDATIONS_PCT' : followed_rec_hi,\n",
    "    'LARGEST_ORDER_SIZE'           : largest_order_size_hi,\n",
    "    'PRODUCT_CATEGORIES_VIEWED'    : products_viewed_hi,\n",
    "    'AVG_CLICKS_PER_VISIT'         : avg_clicks_per_visit_hi,\n",
    "    'PRODUCT_CATEGORIES_VIEWED'    : products_viewed_hi,\n",
    "    'MEDIAN_MEAL_RATING'           : median_meal_hi\n",
    "    }\n",
    "\n",
    "lst_thresholds_lo = {\n",
    "    'AVG_CLICKS_PER_VISIT'          : avg_clicks_per_visit_lo,\n",
    "    'PRODUCT_CATEGORIES_VIEWED'     : products_viewed_lo,\n",
    "    'FOLLOWED_RECOMMENDATIONS_PCT'  : followed_rec_lo,\n",
    "    'UNIQUE_MEALS_PURCH'            : unique_meals_purchased_lo,\n",
    "    'MEDIAN_MEAL_RATING'            : median_meal_lo\n",
    "     }\n",
    "\n",
    "# creating a copy of dataframe for safety measures\n",
    "chef_o = chef_m.copy()\n",
    "\n",
    "# Looping over variables to create outlier flags:\n",
    "for key in lst_thresholds_hi.keys():\n",
    "    outlier_flag_hi(key,lst_thresholds_hi[key],chef_o)\n",
    "    \n",
    "for key in lst_thresholds_lo.keys():\n",
    "    outlier_flag_lo(key,lst_thresholds_lo[key],chef_o)\n",
    "    \n",
    "#merging avg clicks per visit hi and lo\n",
    "chef_o['out_AVG_CLICKS_PER_VISIT'] = chef_o['out_AVG_CLICKS_PER_VISIT_hi'] + chef_o['out_AVG_CLICKS_PER_VISIT_lo'] \n",
    "\n",
    "# STEP 1: splitting emails\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping over each email address\n",
    "for index, col in chef_o.iterrows():\n",
    "    \n",
    "    # splitting email domain at '@'\n",
    "    split_email = chef_o.loc[index, 'EMAIL'].split(sep = '@')\n",
    "\n",
    "    # appending placeholder_lst with the results\n",
    "    placeholder_lst.append(split_email)\n",
    "    \n",
    "# converting placeholder_lst into a DataFrame\n",
    "email_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "# STEP 2: concatenating with original DataFrame\n",
    "# Creating a copy of chef for features and safety measure\n",
    "chef_v = chef_o.copy()\n",
    "\n",
    "# renaming column to concatenate\n",
    "email_df.columns = ['name' , 'EMAIL_DOMAIN'] \n",
    "\n",
    "# concatenating personal_email_domain with chef DataFrame\n",
    "chef_v = pd.concat([chef_v, email_df.loc[:, 'EMAIL_DOMAIN']], \n",
    "                   axis = 1)\n",
    "\n",
    "# printing value counts of personal_email_domain\n",
    "chef_v.loc[: ,'EMAIL_DOMAIN'].value_counts()\n",
    "\n",
    "# email domain types\n",
    "professional_email_domains = ['@mmm.com',         '@amex.com',\n",
    "                              '@apple.com',       '@boeing.com',\n",
    "                              '@caterpillar.com', '@chevron.com',\n",
    "                              '@cisco.com',       '@cocacola.com',\n",
    "                              '@disney.com',      '@dupont.com',\n",
    "                              '@exxon.com',       '@ge.org',\n",
    "                              '@goldmansacs.com', '@homedepot.com',\n",
    "                              '@ibm.com',         '@intel.com',\n",
    "                              '@jnj.com',         '@jpmorgan.com',\n",
    "                              '@mcdonalds.com',   '@merck.com',\n",
    "                              '@microsoft.com',   '@nike.com',\n",
    "                              '@pfizer.com',      '@pg.com',\n",
    "                              '@travelers.com',   '@unitedtech.com',\n",
    "                              '@unitedhealth.com','@verizon.com',\n",
    "                              '@visa.com',        '@walmart.com']\n",
    "personal_email_domains     = ['@gmail.com',       '@yahoo.com',    \n",
    "                              '@protonmail.com']\n",
    "junk_email_domains         = ['@me.com',          '@aol.com',\n",
    "                              '@hotmail.com',     '@live.com', \n",
    "                              '@msn.com',         '@passport.com']\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []  \n",
    "\n",
    "\n",
    "# looping to group observations by domain type\n",
    "for domain in chef_v['EMAIL_DOMAIN']:\n",
    "        if \"@\" + domain in professional_email_domains:\n",
    "            placeholder_lst.append('professional')\n",
    "            \n",
    "        elif \"@\" + domain in personal_email_domains:\n",
    "            placeholder_lst.append('personal')\n",
    "            \n",
    "        elif \"@\" + domain in junk_email_domains:\n",
    "            placeholder_lst.append('junk')\n",
    "            \n",
    "        else:\n",
    "            print('Unknown')\n",
    "\n",
    "\n",
    "# concatenating with original DataFrame\n",
    "chef_v['email_domain_group'] = pd.Series(placeholder_lst)\n",
    "\n",
    "# checking results and sample size\n",
    "#print(chef['email_domain_group'].value_counts())\n",
    "\n",
    "# Step 3: One-Hot encoding\n",
    "one_hot_email_domain = pd.get_dummies(chef_v['email_domain_group'])\n",
    "\n",
    "# dropping orginal columns to keep only encoded ones\n",
    "chef_e               = chef_v.drop(['email_domain_group','EMAIL','EMAIL_DOMAIN'], axis = 1)\n",
    "\n",
    "# joining encoded columns to dataset\n",
    "chef_e               = chef_e.join(one_hot_email_domain)\n",
    "\n",
    "# including new categorical variables to list\n",
    "domains              = ['professional','personal','junk']\n",
    "\n",
    "# creating a copy of dataframe for safety measures\n",
    "chef_n = chef_e.copy()\n",
    "\n",
    "# placeholder for 'rev_per_meal' feature\n",
    "chef_n['rev_per_meal'] = 0\n",
    "\n",
    "# replacing values based on calculation\n",
    "for index, col in chef_n.iterrows():\n",
    "    revenue      = chef_n.loc[index, 'REVENUE']\n",
    "    total_orders = chef_n.loc[index, 'TOTAL_MEALS_ORDERED']\n",
    "    chef_n.loc[index, 'rev_per_meal'] = (revenue / total_orders).round(2)\n",
    "    \n",
    "# Determining Outliers in new variable\n",
    "#distributions('rev_per_meal', chef_n)\n",
    "\n",
    "# Establishing Outlier Flags\n",
    "rev_per_meal_hi = 70\n",
    "rev_per_meal_lo = 15\n",
    "outlier_flag_hi('rev_per_meal', rev_per_meal_hi, chef_n)\n",
    "outlier_flag_lo('rev_per_meal', rev_per_meal_lo, chef_n)\n",
    "\n",
    "# creating a copy of dataframe for safety measures\n",
    "chef_n = chef_n.copy()\n",
    "\n",
    "# new column for 'rev_per_login' feature\n",
    "chef_n['rev_per_pclogin']     = 0\n",
    "chef_n['rev_per_mobilelogin'] = 0\n",
    "\n",
    "# replacing values based on calculation\n",
    "for index, col in chef_n.iterrows():\n",
    "    revenue       = chef_n.loc[index, 'REVENUE']\n",
    "    PC_LOGINS     = chef_n.loc[index, 'PC_LOGINS']\n",
    "    if PC_LOGINS   == 0:\n",
    "        chef_n.loc[index, 'rev_per_pclogin'] = 0\n",
    "    elif PC_LOGINS >= 0:\n",
    "        chef_n.loc[index, 'rev_per_pclogin'] = (revenue / PC_LOGINS).round(2)\n",
    "    else:\n",
    "        print('Something went wrong.')\n",
    "\n",
    "for index, col in chef_n.iterrows():\n",
    "    revenue       = chef_n.loc[index, 'REVENUE']\n",
    "    MOBILE_LOGINS = chef_n.loc[index, 'MOBILE_LOGINS']    \n",
    "    if MOBILE_LOGINS   == 0:\n",
    "        chef_n.loc[index, 'rev_per_mobilelogin'] = 0\n",
    "    elif MOBILE_LOGINS >= 0:\n",
    "        chef_n.loc[index, 'rev_per_mobilelogin'] = (revenue / MOBILE_LOGINS).round(2)\n",
    "    else:\n",
    "        print('Something went wrong.')\n",
    "        \n",
    "# flagging outliers\n",
    "rev_per_pclogin_hi = 800\n",
    "rev_per_pclogin_lo = 150\n",
    "outlier_flag_hi('rev_per_pclogin', rev_per_pclogin_hi, chef_n)\n",
    "outlier_flag_lo('rev_per_pclogin', rev_per_pclogin_lo, chef_n)\n",
    "\n",
    "# flagging outliers\n",
    "rev_per_mobilelogin_hi = 2500\n",
    "rev_per_mobilelogin_lo = 200\n",
    "outlier_flag_hi('rev_per_mobilelogin', rev_per_mobilelogin_hi, chef_n)\n",
    "outlier_flag_lo('rev_per_mobilelogin', rev_per_mobilelogin_lo, chef_n)\n",
    "\n",
    "# Establishing trend thresholds for analysis\n",
    "# above this threshold its a succes\n",
    "followed_recommendations_pct_1 = 20 #(or 30 for certainty)\n",
    "cancellations_before_noon_1    = 2 #(or 1 for mean)\n",
    "median_ratings_1               = 3\n",
    "median_ratings_2               = 2\n",
    "\n",
    "# Creating Dictionary to link variables with outlier thresholds\n",
    "success_trend = {\n",
    "    'FOLLOWED_RECOMMENDATIONS_PCT' : followed_recommendations_pct_1,\n",
    "    'CANCELLATIONS_BEFORE_NOON'    : cancellations_before_noon_1,\n",
    "    'MEDIAN_MEAL_RATING'           : median_ratings_1,\n",
    "    'MEDIAN_MEAL_RATING'           : median_ratings_2\n",
    "     }\n",
    "\n",
    "# creating a copy of dataframe for safety measures\n",
    "chef_t = chef_n.copy()\n",
    "\n",
    "# Looping over variables to create trend flags:\n",
    "for key in success_trend.keys():\n",
    "    success_flag(key,success_trend[key],chef_t)\n",
    "    \n",
    "# creating a copy for safety measures\n",
    "chef = chef_t.copy()\n",
    "\n",
    "# dropping discrete variables (only run once!)\n",
    "chef = chef.drop(['NAME', 'FIRST_NAME', 'FAMILY_NAME'], axis = 1)\n",
    "\n",
    "# Defining a dictionary with explanatory variables names \n",
    "variables_dict = {\n",
    "    \"target\"     : [    # target variable\n",
    "        'CROSS_SELL_SUCCESS'\n",
    "    ],\n",
    "    'Best Model' : [\n",
    "        'EARLY_DELIVERIES',\n",
    "          'MOBILE_NUMBER','CANCELLATIONS_BEFORE_NOON',\n",
    "          'CANCELLATIONS_AFTER_NOON','TASTES_AND_PREFERENCES',\n",
    "          'REFRIGERATED_LOCKER','FOLLOWED_RECOMMENDATIONS_PCT',\n",
    "          'personal','professional','junk',\n",
    "          'out_FOLLOWED_RECOMMENDATIONS_PCT_hi',\n",
    "          'out_FOLLOWED_RECOMMENDATIONS_PCT_lo',\n",
    "          'out_PRODUCT_CATEGORIES_VIEWED_hi',\n",
    "          'out_PRODUCT_CATEGORIES_VIEWED_lo',\n",
    "          'out_MEDIAN_MEAL_RATING_hi',\n",
    "          'out_MEDIAN_MEAL_RATING_lo',\n",
    "          'rev_per_mobilelogin',\n",
    "          'out_rev_per_pclogin_hi',\n",
    "          'out_rev_per_pclogin_lo',\n",
    "          'out_rev_per_mobilelogin_hi',\n",
    "          'out_rev_per_mobilelogin_lo',\n",
    "          'success_FOLLOWED_RECOMMENDATIONS_PCT'\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "# setting random state\n",
    "seed = 222\n",
    "\n",
    "# Defining target variable\n",
    "chef_target = chef.loc[: , variables_dict['target']]\n",
    "\n",
    "###### Non Standardized Preparation \n",
    "# Defining explanatory variables (add according to new feature selections)\n",
    "chef_best = chef.loc[: , variables_dict['Best Model']]\n",
    "\n",
    "# train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            chef_best,  # change\n",
    "            chef_target,\n",
    "            test_size = 0.25,\n",
    "            random_state = seed,\n",
    "            stratify = chef_target) # stratifying target variable to ensure balance\n",
    "\n",
    "# merging training data for statsmodels\n",
    "chef_train = pd.concat([X_train, y_train], axis = 1) # contains target variable!\n",
    "\n",
    "################################################################################\n",
    "# Final Model (instantiate, fit, and predict)\n",
    "################################################################################\n",
    "\n",
    "# declaring a hyperparameter space\n",
    "#criterion_space = ['gini', 'entropy']\n",
    "#splitter_space = ['best', 'random']\n",
    "#depth_space    = pd.np.arange(1, 25)\n",
    "#leaf_space     = pd.np.arange(1, 100)\n",
    "#\n",
    "#\n",
    "## creating a hyperparameter grid\n",
    "#param_grid = {'criterion'        : criterion_space,\n",
    "#              'splitter'         : splitter_space,\n",
    "#              'max_depth'        : depth_space,\n",
    "#              'min_samples_leaf' : leaf_space}\n",
    "#\n",
    "#\n",
    "## INSTANTIATING the model object without hyperparameters\n",
    "#tuned_tree = DecisionTreeClassifier(random_state = seed)\n",
    "#\n",
    "\n",
    "# GridSearchCV object\n",
    "#tuned_tree_cv = GridSearchCV(estimator  = tuned_tree,\n",
    "#                             param_grid = param_grid,\n",
    "#                             cv         = 3,\n",
    "#                             scoring    = make_scorer(roc_auc_score,\n",
    "#                                                      needs_threshold = False))\n",
    "#\n",
    "\n",
    "# INSTANTIATING a logistic regression model with tuned values\n",
    "tree_tuned = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
    "                                    max_depth=18, max_features=None, max_leaf_nodes=None,\n",
    "                                    min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                    min_samples_leaf=2, min_samples_split=2,\n",
    "                                    min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "                                    random_state=seed, splitter='random')\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation from GridSearch)\n",
    "tree_tuned.fit(chef_best, chef_target)\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "tree_tuned_pred = tree_tuned.predict(X_test)\n",
    "\n",
    "## printing the optimal parameters and best score\n",
    "#print(\"Tuned Parameters  :\", tuned_tree_cv.best_params_)\n",
    "#print(\"Tuned Training AUC:\", tuned_tree_cv.best_score_.round(4))\n",
    "\n",
    "################################################################################\n",
    "# Final Model Score (score)\n",
    "################################################################################\n",
    "\n",
    "test_score       = roc_auc_score(y_true  = y_test,\n",
    "                               y_score = tree_tuned_pred).round(3)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
