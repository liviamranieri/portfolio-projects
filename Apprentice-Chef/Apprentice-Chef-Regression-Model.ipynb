{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeit\n",
    "\n",
    "# Student Name : Sophie Briques\n",
    "# Cohort       : Castro - 3\n",
    "\n",
    "################################################################################\n",
    "# Import Packages\n",
    "################################################################################\n",
    "\n",
    "import pandas  as pd   # data science essentials\n",
    "import numpy   as np   \n",
    "from   sklearn.model_selection import train_test_split    # train test split\n",
    "from   sklearn.preprocessing   import StandardScaler      # standard scaler\n",
    "from   sklearn.linear_model    import LinearRegression    # linear regression (scikit-learn)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Load Data\n",
    "################################################################################\n",
    "\n",
    "# specifying file name\n",
    "file = \"Apprentice_Chef_Dataset.xlsx\"\n",
    "\n",
    "# reading the file into Python\n",
    "original_df = pd.read_excel(file)\n",
    "chef_org = original_df.copy()\n",
    "\n",
    "################################################################################\n",
    "# Feature Engineering and (optional) Dataset Standardization\n",
    "################################################################################\n",
    "\n",
    "#################################################\n",
    "##########  User-Defined Functions    ###########\n",
    "#################################################\n",
    "\n",
    "# Defining function to flag high outliers in variables\n",
    "def outlier_flag_hi(variable, threshold, data):\n",
    "    \"\"\"\n",
    "    This function is used to flag high outliers in a dataframe the variables' \n",
    "    outliers by creating a new column that is preceded by 'out_'.\n",
    "\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    variable  : str, continuous variable.\n",
    "    threshold : float, value that will identify where outliers would be.\n",
    "    data      : dataframe, where the variables are located.\n",
    "    \n",
    "    \"\"\"\n",
    "    # creating a new column\n",
    "    data['out_' + variable] = 0\n",
    "        \n",
    "    # defining outlier condition\n",
    "    high = data.loc[0:,'out_' + variable][data[variable] > threshold]\n",
    "        \n",
    "    # imputing 1 inside flag column\n",
    "    data['out_' + variable].replace(to_replace = high,\n",
    "                                    value   = 1,\n",
    "                                    inplace = True)\n",
    "\n",
    "# Defining function to flag high outliers in variables\n",
    "def outlier_flag_lo(variable, threshold, data):\n",
    "    \"\"\"\n",
    "    This function is used to flag low outliers in a dataframe the variables' \n",
    "    outliers by creating a new column that is preceded by 'out_'.\n",
    "\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    variable  : str, continuous variable.\n",
    "    threshold : float, value that will identify where outliers would be.\n",
    "    data      : dataframe, where the variables are located.\n",
    "    \n",
    "    \"\"\"\n",
    "    # creating a new column\n",
    "    data['out_' + variable] = 0\n",
    "        \n",
    "    # defining outlier condition\n",
    "    low = data.loc[0:,'out_' + variable][data[variable] < threshold]\n",
    "        \n",
    "    # imputing 1 inside flag column\n",
    "    data['out_' + variable].replace(to_replace = low,\n",
    "                                    value   = 1,\n",
    "                                    inplace = True)\n",
    "\n",
    "    \n",
    "# Defining function to flag higher variables\n",
    "def higher_change_flag(variable, index, threshold, data):\n",
    "    \"\"\"\n",
    "    This function is used to flag in a dataframe the variables' trend changes\n",
    "    above a threshold by creating a new column that is preceded by 'change_'.\n",
    "\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    variable  : str, continuous variable.\n",
    "    threshold : float, value that will identify after which the trend on\n",
    "                variable y changes\n",
    "    data      : dataframe, where the variables are located.\n",
    "    \n",
    "    \"\"\"\n",
    "    new_column = 'change_' + variable + \"_\" + str(index)\n",
    "    \n",
    "    # creating a new column\n",
    "    data[new_column] = 0\n",
    "        \n",
    "    # defining outlier condition\n",
    "    high = data.loc[0:,new_column][data[variable] > threshold]\n",
    "        \n",
    "    # imputing 1 inside flag column\n",
    "    data[new_column].replace(to_replace = high,\n",
    "                                       value   = 1,\n",
    "                                       inplace = True)\n",
    "    \n",
    "    \n",
    "# Defining function to flag change at variables\n",
    "def at_flag(variable, index, threshold, data):\n",
    "    \"\"\"\n",
    "    This function is used to flag in a dataframe the variables' trend changes\n",
    "    at a threshold by creating a new column that is preceded by 'change_'.\n",
    "\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    variable  : str, continuous variable.\n",
    "    threshold : float, value that will identify after which the trend on \n",
    "                variable y changes\n",
    "    data      : dataframe, where the variables are located.\n",
    "    \n",
    "    \"\"\"\n",
    "    new_column = 'change_' + variable + \"_\" + str(index)\n",
    "    \n",
    "    # creating a new column\n",
    "    data[new_column] = 0\n",
    "        \n",
    "    # defining outlier condition\n",
    "    high = data.loc[0:,new_column][data[variable] == threshold]\n",
    "        \n",
    "    # imputing 1 inside flag column\n",
    "    data[new_column].replace(to_replace = high,\n",
    "                                       value   = 1,\n",
    "                                       inplace = True)\n",
    "\n",
    "#Defining a function to standardize numerical variables in the dataset:\n",
    "def standard(num_df):\n",
    "    \"\"\"\n",
    "    This function standardizes a dataframe that contains variables which are \n",
    "    either integers or floats.\n",
    "    \n",
    "    ------\n",
    "    num_df : DataFrame, must contain only numerical variables\n",
    "    \n",
    "    \"\"\"\n",
    "    # Isolating target variable from DF to be standardized\n",
    "    #num_df = num_df.drop(target_variable, axis = 1)\n",
    "    \n",
    "    # INSTANTIATING a StandardScaler() object\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # FITTING the scaler with housing_data\n",
    "    scaler.fit(num_df)\n",
    "\n",
    "    # TRANSFORMING our data after fit\n",
    "    X_scaled = scaler.transform(num_df)\n",
    "\n",
    "\n",
    "    # converting scaled data into a DataFrame\n",
    "    X_scaled_df = pd.DataFrame(X_scaled)\n",
    "    \n",
    "    # adding labels to the scaled DataFrame\n",
    "    X_scaled_df.columns = num_df.columns\n",
    "    \n",
    "    # Re-attaching target variable to DataFrame\n",
    "    #X_scaled_df = X_scaled_df.join(target_variable)\n",
    "    \n",
    "    # returning the standardized data frame into the global environment\n",
    "    return X_scaled_df\n",
    "\n",
    "\n",
    "#################################################\n",
    "#############  Feature Engineering    ###########\n",
    "#################################################\n",
    "\n",
    "# Flagging missing variables for FAMILY_NAME\n",
    "# creating a copy of dataframe for safety measures\n",
    "chef_m = chef_org.copy()\n",
    "\n",
    "# creating a new column where 1 indicates that observation has a missing family name\n",
    "chef_m['m_FAMILY_NAME'] = chef_m['FAMILY_NAME'].isnull().astype(int)\n",
    "\n",
    "\n",
    "# Creating Email Domain Categories\n",
    "# STEP 1: splitting emails\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping over each email address\n",
    "for index, col in chef_org.iterrows():\n",
    "    \n",
    "    # splitting email domain at '@'\n",
    "    split_email = chef_m.loc[index, 'EMAIL'].split(sep = '@')\n",
    "\n",
    "    # appending placeholder_lst with the results\n",
    "    placeholder_lst.append(split_email)\n",
    "    \n",
    "# converting placeholder_lst into a DataFrame\n",
    "email_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "# STEP 2: concatenating with original DataFrame\n",
    "# Creating a copy of chef for features and safety measure\n",
    "chef = chef_m.copy()\n",
    "\n",
    "# renaming column to concatenate\n",
    "email_df.columns = ['name' , 'EMAIL_DOMAIN'] \n",
    "\n",
    "# concatenating personal_email_domain with chef DataFrame\n",
    "chef = pd.concat([chef, email_df.loc[:, 'EMAIL_DOMAIN']], \n",
    "                   axis = 1)\n",
    "\n",
    "# printing value counts of personal_email_domain\n",
    "chef.loc[: ,'EMAIL_DOMAIN'].value_counts()\n",
    "\n",
    "# email domain types\n",
    "professional_email_domains = [\n",
    "    '@mmm.com',         '@amex.com',\n",
    "    '@apple.com',       '@boeing.com',\n",
    "    '@caterpillar.com', '@chevron.com',\n",
    "    '@cisco.com',       '@cocacola.com',\n",
    "    '@disney.com',      '@dupont.com',\n",
    "    '@exxon.com',       '@ge.org',\n",
    "    '@goldmansacs.com', '@homedepot.com',\n",
    "    '@ibm.com',         '@intel.com',\n",
    "    '@jnj.com',         '@jpmorgan.com',\n",
    "    '@mcdonalds.com',   '@merck.com',\n",
    "    '@microsoft.com',   '@nike.com',\n",
    "    '@pfizer.com',      '@pg.com',\n",
    "    '@travelers.com',   '@unitedtech.com',\n",
    "    '@unitedhealth.com','@verizon.com',\n",
    "    '@visa.com',        '@walmart.com'\n",
    "    ]\n",
    "\n",
    "personal_email_domains = [\n",
    "    '@gmail.com',       '@yahoo.com',    \n",
    "    '@protonmail.com'\n",
    "    ]\n",
    "\n",
    "junk_email_domains = [\n",
    "    '@me.com',          '@aol.com',\n",
    "    '@hotmail.com',     '@live.com', \n",
    "    '@msn.com',         '@passport.com'\n",
    "    ]\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []  \n",
    "\n",
    "# looping to group observations by domain type\n",
    "for domain in chef['EMAIL_DOMAIN']:\n",
    "        if \"@\" + domain in professional_email_domains:\n",
    "            placeholder_lst.append('professional')\n",
    "            \n",
    "            \n",
    "        elif \"@\" + domain in personal_email_domains:\n",
    "            placeholder_lst.append('personal')\n",
    "            \n",
    "            \n",
    "        elif \"@\" + domain in junk_email_domains:\n",
    "            placeholder_lst.append('junk')\n",
    "            \n",
    "        else:\n",
    "            print('Unknown')\n",
    "\n",
    "            \n",
    "# concatenating with original DataFrame\n",
    "chef['email_domain_group'] = pd.Series(placeholder_lst)\n",
    "\n",
    "# Step 3: One-Hot encoding\n",
    "one_hot_email_domain = pd.get_dummies(chef['email_domain_group'])\n",
    "\n",
    "# dropping orginal columns to keep only encoded ones\n",
    "chef_1               = chef.drop(['email_domain_group','EMAIL','EMAIL_DOMAIN'], axis = 1)\n",
    "\n",
    "# joining encoded columns to dataset\n",
    "chef_1               = chef_1.join(one_hot_email_domain)\n",
    "\n",
    "\n",
    "# Establishing outliers thresholds for analysis\n",
    "# Continous\n",
    "avg_time_per_site_visit_hi = 200\n",
    "avg_prep_vid_time_hi       = 250\n",
    "followed_rec_hi            = 80\n",
    "largest_order_size_hi      = 5\n",
    "avg_clicks_per_visit_lo    = 10\n",
    "\n",
    "# Counts:\n",
    "total_meals_ordered_hi            = 320\n",
    "unique_meals_purchased_hi         = 10\n",
    "contacts_with_customer_service_hi = 13\n",
    "cancellations_before_noon_hi      = 8\n",
    "late_deliveries_hi                = 17\n",
    "total_photos_viewed_hi            = 800\n",
    "\n",
    "# Target Variable\n",
    "revenue_hi  =  5500\n",
    "\n",
    "# Creating Dictionary to link variables with outlier thresholds\n",
    "lst_thresholds_hi = {\n",
    "    'AVG_TIME_PER_SITE_VISIT'      : avg_time_per_site_visit_hi,\n",
    "    'AVG_PREP_VID_TIME'            : avg_prep_vid_time_hi,\n",
    "    'TOTAL_MEALS_ORDERED'          : total_meals_ordered_hi,\n",
    "    'UNIQUE_MEALS_PURCH'           : unique_meals_purchased_hi,\n",
    "    'CONTACTS_W_CUSTOMER_SERVICE'  : contacts_with_customer_service_hi,\n",
    "    'CANCELLATIONS_BEFORE_NOON'    : cancellations_before_noon_hi,\n",
    "    'LATE_DELIVERIES'              : late_deliveries_hi,\n",
    "    'TOTAL_PHOTOS_VIEWED'          : total_photos_viewed_hi,\n",
    "    'REVENUE'                      : revenue_hi,\n",
    "    'FOLLOWED_RECOMMENDATIONS_PCT' : followed_rec_hi,\n",
    "    'LARGEST_ORDER_SIZE'           : largest_order_size_hi\n",
    "    }\n",
    "\n",
    "lst_thresholds_lo = {\n",
    "    'AVG_CLICKS_PER_VISIT'         : avg_clicks_per_visit_lo\n",
    "    }\n",
    "\n",
    "# Looping over variables to create outlier flags:\n",
    "for key in lst_thresholds_hi.keys():\n",
    "    outlier_flag_hi(key,lst_thresholds_hi[key],chef_1)\n",
    "    \n",
    "for key in lst_thresholds_lo.keys():\n",
    "    outlier_flag_lo(key,lst_thresholds_lo[key],chef_1)\n",
    "\n",
    "    \n",
    "# Establishing outliers thresholds for analysis\n",
    "# data scatters above this point\n",
    "AVG_TIME_PER_SITE_VISIT_change_hi      = 200\n",
    "FOLLOWED_RECOMMENDATIONS_PCT_change_hi = 70\n",
    "AVG_PREP_VID_TIME_change_lo            = 150\n",
    "AVG_PREP_VID_TIME_change_hi            = 210\n",
    "TOTAL_MEALS_ORDERED_change_hi          = 100\n",
    "\n",
    "# trend changes\n",
    "LARGEST_ORDER_SIZE_change_hi          = 5\n",
    "AVG_CLICKS_PER_VISIT_change_lo        = 8\n",
    "AVG_CLICKS_PER_VISIT_change_hi        = 16\n",
    "UNIQUE_MEALS_PURCH_change_hi          = 9\n",
    "CONTACTS_W_CUSTOMER_SERVICE_change_hi = 10\n",
    "PRODUCT_CATEGORIES_VIEWED_change_hi   = 5\n",
    "CANCELLATIONS_BEFORE_NOON_change_hi   = 8\n",
    "MOBILE_LOGINS_change_hi               = 1\n",
    "PC_LOGINS_change_hi                   = 6\n",
    "WEEKLY_PLAN_change_hi                 = 15\n",
    "LATE_DELIVERIES_change_lo             = 8\n",
    "TOTAL_MEALS_ORDERED_change_hi         = 100\n",
    "\n",
    "\n",
    "# Different at __ \n",
    "AVG_TIME_PER_SITE_VISIT_change_at   = 50\n",
    "MEDIAN_MEAL_RATING_change_at1       = 3\n",
    "MEDIAN_MEAL_RATING_change_at2       = 4\n",
    "MEDIAN_MEAL_RATING_change_at3       = 5\n",
    "TOTAL_MEALS_ORDERED_change_at       = 15\n",
    "UNIQUE_MEALS_PURCH_change_at        = 1\n",
    "CANCELLATIONS_AFTER_NOON_change_at  = 0\n",
    "MASTER_CLASSES_ATTENDED_change_at1  = 1\n",
    "MASTER_CLASSES_ATTENDED_change_at2  = 2\n",
    "\n",
    "\n",
    "# Zero Inflated\n",
    "TOTAL_PHOTOS_VIEWED_change_at = 0 \n",
    "\n",
    "# Creating Dictionary to link variables with trend thresholds\n",
    "high_thresholds = {\n",
    "    'AVG_TIME_PER_SITE_VISIT'        : [AVG_TIME_PER_SITE_VISIT_change_hi],\n",
    "    'FOLLOWED_RECOMMENDATIONS_PCT'   : [FOLLOWED_RECOMMENDATIONS_PCT_change_hi],\n",
    "    'AVG_PREP_VID_TIME'              : [AVG_PREP_VID_TIME_change_hi,\n",
    "                                        AVG_PREP_VID_TIME_change_lo],\n",
    "    'TOTAL_MEALS_ORDERED'            : [TOTAL_MEALS_ORDERED_change_hi],\n",
    "    'LARGEST_ORDER_SIZE'             : [LARGEST_ORDER_SIZE_change_hi],\n",
    "    'AVG_CLICKS_PER_VISIT'           : [AVG_CLICKS_PER_VISIT_change_lo, \n",
    "                                        AVG_CLICKS_PER_VISIT_change_hi],\n",
    "    'UNIQUE_MEALS_PURCH'             : [UNIQUE_MEALS_PURCH_change_hi],\n",
    "    'CONTACTS_W_CUSTOMER_SERVICE'    : [CONTACTS_W_CUSTOMER_SERVICE_change_hi],\n",
    "    'PRODUCT_CATEGORIES_VIEWED'      : [PRODUCT_CATEGORIES_VIEWED_change_hi],\n",
    "    'CANCELLATIONS_BEFORE_NOON'      : [CANCELLATIONS_BEFORE_NOON_change_hi],\n",
    "    'MOBILE_LOGINS'                  : [MOBILE_LOGINS_change_hi],\n",
    "    'PC_LOGINS'                      : [PC_LOGINS_change_hi],\n",
    "    'WEEKLY_PLAN'                    : [WEEKLY_PLAN_change_hi],\n",
    "    'LATE_DELIVERIES'                : [LATE_DELIVERIES_change_lo],\n",
    "    'TOTAL_MEALS_ORDERED'            : [TOTAL_MEALS_ORDERED_change_hi]\n",
    "    }\n",
    "                     \n",
    "                     \n",
    "at_thresholds = {\n",
    "    'AVG_TIME_PER_SITE_VISIT'      : [AVG_TIME_PER_SITE_VISIT_change_at],\n",
    "    'MEDIAN_MEAL_RATING'           : [MEDIAN_MEAL_RATING_change_at1, \n",
    "                                       MEDIAN_MEAL_RATING_change_at2, \n",
    "                                       MEDIAN_MEAL_RATING_change_at3],\n",
    "    'UNIQUE_MEALS_PURCH'           : [UNIQUE_MEALS_PURCH_change_at],\n",
    "    'CANCELLATIONS_BEFORE_NOON'    : [CANCELLATIONS_AFTER_NOON_change_at],\n",
    "    'MASTER_CLASSES_ATTENDED'      : [MASTER_CLASSES_ATTENDED_change_at1,\n",
    "                                       MASTER_CLASSES_ATTENDED_change_at2],\n",
    "    'TOTAL_PHOTOS_VIEWED'          : [TOTAL_PHOTOS_VIEWED_change_at]\n",
    "    }\n",
    "\n",
    "# Looping over dataset to create trend based columns\n",
    "for key, value in high_thresholds.items():\n",
    "    i = 0\n",
    "    for val in value:\n",
    "        higher_change_flag(key, i, val, chef_1)\n",
    "        i += 1\n",
    "\n",
    "for key, value in at_thresholds.items():\n",
    "    i = 0\n",
    "    for val in value:\n",
    "        at_flag(key, i, val, chef_1)\n",
    "        i += 1    \n",
    "    \n",
    "# Dropping variables after feature engineering\n",
    "clean_chef = chef_1.drop([\n",
    "                          'CROSS_SELL_SUCCESS',\n",
    "                          'NAME',\n",
    "                          'FIRST_NAME',\n",
    "                          'FAMILY_NAME',\n",
    "                          'm_FAMILY_NAME'\n",
    "                          ], axis = 1)    \n",
    "\n",
    "\n",
    "#################################################\n",
    "#############    Transformations      ###########\n",
    "#################################################\n",
    "\n",
    "# Log Transformation\n",
    "# creating a copy for safety measures\n",
    "clean_chef = clean_chef.copy()\n",
    "\n",
    "#transforming only REVENUE column\n",
    "clean_chef['rev_log'] = clean_chef['REVENUE'].transform(np.log)\n",
    "\n",
    "\n",
    "# Standardization\n",
    "# creating a copy for safety measures\n",
    "clean_chef = clean_chef.copy()\n",
    "\n",
    "# dropping revenue from standardization\n",
    "chef_x      = clean_chef.drop(['REVENUE','rev_log'], axis = 1)\n",
    "#clean_chef.columns\n",
    "chef_target = clean_chef.loc[:,['REVENUE','rev_log']]\n",
    "\n",
    "# standardizing with user defined function and joining target revenue\n",
    "chef_std   = standard(chef_x).join(chef_target)\n",
    "\n",
    "# Outliers\n",
    "# Creating a copy of dataset for safety measure\n",
    "out_chef = clean_chef.copy()\n",
    "\n",
    "# Subsetting outliers from our linear model features by using flags\n",
    "out_chef = out_chef.loc[:][out_chef['out_TOTAL_MEALS_ORDERED'] == 0]\n",
    "\n",
    "\n",
    "# Defining a dictionary with variables names\n",
    "variables_dict = {\n",
    "    \"ARD Features\" : [\n",
    "        'REVENUE',                     'TOTAL_MEALS_ORDERED',  \n",
    "        'CONTACTS_W_CUSTOMER_SERVICE', 'AVG_PREP_VID_TIME',\n",
    "        'LARGEST_ORDER_SIZE',          'MEDIAN_MEAL_RATING', \n",
    "        'out_TOTAL_MEALS_ORDERED',     'out_CONTACTS_W_CUSTOMER_SERVICE', \n",
    "        'change_AVG_PREP_VID_TIME_1',  'change_UNIQUE_MEALS_PURCH_0', \n",
    "        'change_CONTACTS_W_CUSTOMER_SERVICE_0',  \n",
    "        'change_MEDIAN_MEAL_RATING_0',         'change_MEDIAN_MEAL_RATING_1',\n",
    "        'change_MASTER_CLASSES_ATTENDED_0',    'change_MASTER_CLASSES_ATTENDED_1', \n",
    "        'change_TOTAL_PHOTOS_VIEWED_0',        'rev_log'\n",
    "        ]\n",
    "      }\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Train/Test Split\n",
    "################################################################################\n",
    "\n",
    "# Creating a variable for random seed\n",
    "seed = 222\n",
    "\n",
    "# Preparing response variable\n",
    "out_chef_target = out_chef['rev_log']\n",
    "\n",
    "# Preparing x-variables\n",
    "out_chef_x = out_chef[variables_dict['ARD Features']].drop(['REVENUE','rev_log'], axis = 1)\n",
    "\n",
    "# Running train/test split\n",
    "X_train_out, X_test_out, y_train_out, y_test_out = train_test_split(\n",
    "            out_chef_x,\n",
    "            out_chef_target,\n",
    "            test_size = 0.25,\n",
    "            random_state = seed)\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Final Model (instantiate, fit, and predict)\n",
    "################################################################################\n",
    "\n",
    "# INSTANTIATING a model object\n",
    "out_lr = LinearRegression()\n",
    "\n",
    "# FITTING to the training data\n",
    "out_lr_fit = out_lr.fit(X_train_out, y_train_out) \n",
    "\n",
    "# PREDICTING on new data\n",
    "out_lr_pred = out_lr_fit.predict(X_test_out) \n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Final Model Score (score)\n",
    "################################################################################\n",
    "\n",
    "test_score = out_lr.score(X_test_out,  y_test_out).round(3)\n",
    "test_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
